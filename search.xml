<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[OpenCV的Python实践(5)]]></title>
    <url>%2F2019%2F05%2F20%2FOpenCvPythonPractice-5%2F</url>
    <content type="text"><![CDATA[Meanshift算法(视频分析) 在视频中找到并跟踪目标对象 Camshift算法(视频分析)在视频中找到并跟踪目标对象 Lucas-Kanade光流BackgroundSubtractorMOG前/背景分割算法静态背景图像估计 BackgroundSubtractorMOG2前/背景分割算法每个像素的贝叶斯分割 BackgroundSubtractorGMG分割算法结合了静态背景图像估计和每个像素的贝叶斯分割 摄像机标定对畸变图像进行修复 姿势估计3D效果 对极几何，对极约束立体图像的深度地图机器学习-K近邻找出测试数据在特征空间中的最近的邻居。 支持向量机SVMK值聚类计算摄影学 图像去噪 图像修补 Haar分类器进行面部检测(眼部检测)]]></content>
      <categories>
        <category>OpenCV的Python实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenCV的Python实践(4)]]></title>
    <url>%2F2019%2F05%2F19%2FOpenCvPythonPractice-4%2F</url>
    <content type="text"><![CDATA[直方图反向投影 &emsp;&emsp;直方图反向投影用来做图像分割，或者在图像中寻找感兴趣的部分。&emsp;&emsp;简单来说，直方图反向投影会输出与输入图像(待搜索)同样大小的图像，其中的每一个像素值代表输入图像上对应点属于目标对象的概率，用更简单的话说，输出图像中像素值越高(越白)的点，越可能代表我们要搜素的目标(在输入图像所在的位置)。&emsp;&emsp;如何实现这个算法呢？ 首先要为一张包含我们待查找目标的图像创建直方图，最好使用颜色直方图，因为一个物体的颜色要比灰度更好的被用来进行图像分割与对象识别。 把这个颜色直方图投影到输入图像中寻找我们的目标。也就是找到输入图像中的每一个像素点的像素值在直方图中对应的概率，得到一个概率图像。 最后设置适当的阈值，对概率图像进行而二值化。就这么简单。 Numpy中的算法： 首先创建两幅颜色直方图，目标图像(待搜索)的直方图(‘M’)，输入图像直方图(‘I’) 计算比值R=M/I,得到反向投影R，根据R这个调色板创建一幅新图像，其中每一个像素代表这个点就是目标的概率。输出图像中灰度值最大的地方就是要查找的目标的位置，如果要找的是一个区域，使用一个阈值对图像进行二值化后可得到结果。 12345678910111213141516171819202122232425262728293031#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)target=cv2.imread('psbPart.jpg')hsvt=cv2.cvtColor(target,cv2.COLOR_BGR2HSV)M=cv2.calcHist([hsv],[0,1],None,[180,256],[0,180,0,256])I=cv2.calcHist([hsvt],[0,1],None,[180,256],[0,180,0,256])#代码有问题 圆盘算子做卷积 B=D x B 其中D为卷积核''' h,s,v=cv2.split(hsvt)B=R[h.ravel(),s.ravel()]B=np.minimum(B,1)B=B.reshape(hsvt.shape[:2])disc=cv2.getStructuringElement(cv2.MORPH_ELLTPSE,(5,5))B=cv2.filter2D(B,-1,disc)B=np.uint8(B)cv2.normalize(B,B,0,255,cv2.NORM_MINMAX)ret,thresh=cv2.threshold(B,50,255,0)''' OpenCV中的直方图反向投影&emsp;&emsp;OpenCV提供cv2.calcBackProject()做直方图投影。其参数与cv2.calHist基本相同。其中一个参数是我们要查找目标的直方图，同样再使用目标的直方图做反向投影之前，我们应该先对其做归一化处理。返回结果是一个概率图像，再使用圆盘形卷积核对其做卷操作，最后使用阈值进行二值化。 12345678910111213141516171819202122232425262728293031323334353637#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#在输入图像中搜索目标图像import cv2import numpy as npsmallimg_ToFind = cv2.imread('hair.jpg')hsv=cv2.cvtColor(smallimg_ToFind,cv2.COLOR_BGR2HSV)inputImg=cv2.imread('psb.jpg')hsvt=cv2.cvtColor(inputImg,cv2.COLOR_BGR2HSV)hsvhist=cv2.calcHist([hsv],[0,1],None,[180,256],[0,180,0,256])#归一化：原始图像，结果图像，映射到结果图像中的最小最大值，归一化类型#cv2.NORM_MINMAX 对数组所有值进行转化，使它们线性映射到最小值和最大值之间#归一化后的直方图便于显示，成为0到255之间的数。cv2.normalize(hsvhist,hsvhist,0,255,cv2.NORM_MINMAX);dst=cv2.calcBackProject([hsvt],[0,1],hsvhist,[0,180,0,256],1)#此处卷积把分散的点连在一起disc=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))dst=cv2.filter2D(dst,-1,disc)ret,thresh=cv2.threshold(dst,50,255,0)thresh=cv2.merge((thresh,thresh,thresh))#裁剪res=cv2.bitwise_and(inputImg,thresh)res=np.hstack((inputImg,thresh,res))while(1): cv2.imshow('res',res) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() 傅里叶变换&emsp;&emsp;傅里叶变换用于分析不同滤波器的频率特性，我们可以使用2D离散傅里叶变换（DFT）分析图像的频域特性。实现DFT的快速算法被称为快速傅里叶变化（FFT）。&emsp;&emsp;对于一个正弦信号，频率为f，如果把它转到频域表示，会在频率f中看到一个峰值，如果信号由采样产生的离散信号组成，会得到类似的频谱图，只不过前面是连续的，现在是离散的。把图像想象成沿两个方向采集的信号。所以对图像同时进行X方向和Y方向的傅里叶变换，就会得到这幅图像的频域表示（频谱图）。 Numpy中的傅里叶变换&emsp;&emsp;np.fft.fft2()可对信号进行频率转换，输出结果是一个复杂的数组。第一个参数是输入图像(要求灰度图)，第二个参数可选，决定输出数组的大小。默认输出数组大小和输入图像的数组大小一样，如果输出结果比输入图像大，输入图像在进行FFT前补0，如果输出结果比输入图像小，输入图像就会被切割。&emsp;&emsp;np.fft.fft2()的结果，频率为0的部分(直流分量)在输出图像的左上角，如果想让它在输出图像的中心，需将结果沿两个方向平移N/2,函数np.fft.fftshift()可以实现这一步。&emsp;&emsp;进行完频率变换后，就可以构建振幅谱了。 1234567891011121314151617181920#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg=cv2.imread("psb.jpg",0)f=np.fft.fft2(img)fshift=np.fft.fftshift(f)magnitude_spectrum=20*np.log(np.abs(fshift))plt.subplot(121),plt.imshow(img,cmap='gray')plt.title('Input Image'),plt.xticks([]),plt.yticks([])plt.subplot(122),plt.imshow(magnitude_spectrum,cmap='gray')plt.title('Magnitude Spectrum'),plt.xticks([]),plt.yticks([])plt.show() 现在进行频域变换，我们可以在频域对图像进行一些操作。例如高通滤波和重建图像（DFT的逆变换）。比如使用一个60x60的矩形窗口对图像进行掩模操作从而去除低频分量。然后在使用函数np.fft.ifftshift()进行逆平移操作，所以直流分量又回到左上角了，然后使用np.ifft2()进行FFT逆变换，同样得到一堆复杂的数字，对他们取绝对值。123456789101112131415161718192021222324252627282930#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#高通滤波import cv2import numpy as npfrom matplotlib import pyplot as pltimg=cv2.imread("1.jpg",0)f=np.fft.fft2(img)fshift=np.fft.fftshift(f)magnitude_spectrum=20*np.log(np.abs(fshift))rows,cols=img.shapecrow,ccol=rows/2,cols/2fshift[int(crow-30):int(crow+30),int(ccol-30):int(ccol+30)]=0f_ishift=np.fft.ifftshift(fshift)img_back=np.fft.ifft2(f_ishift)img_back=np.abs(img_back)plt.subplot(131),plt.imshow(img,cmap='gray')plt.title('Input Image'),plt.xticks([]),plt.yticks([])plt.subplot(132),plt.imshow(img_back,cmap='gray')plt.title('Image after HPF'),plt.xticks([]),plt.yticks([])plt.subplot(133),plt.imshow(img_back)plt.title('Result in JET'),plt.xticks([]),plt.yticks([])plt.show() 上面的高通滤波其实是一种边界检测操作。&emsp;&emsp;图像的大部分数据集中在频谱图的低频区域。 OpenCV中的傅里叶变换&emsp;&emsp;OpenCV相应的函数为cv2.dft()和cv2.idft,和前面的输出结果一样，但是是双通道的。第一个通道是结果的实数部分，第二个通道是结果的虚数部分。输入图像首先转换成np.float32格式。 123456789101112131415161718192021#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg=cv2.imread("psb.jpg",0)dft=cv2.dft(np.float32(img),flags=cv2.DFT_COMPLEX_OUTPUT)dft_shift=np.fft.fftshift(dft)magnitude_spectrum=20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))plt.subplot(121),plt.imshow(img,cmap='gray')plt.title('Input Image'),plt.xticks([]),plt.yticks([])plt.subplot(122),plt.imshow(magnitude_spectrum,cmap='gray')plt.title('magnitude_spectrum'),plt.xticks([]),plt.yticks([])plt.show() 前面我们实现了一个HPF高通滤波，现在我们来做LPF(低通滤波)将高频部分出去除。其实就是对图像进行模糊操作。首先我们需要构建一个掩模，与低频区域对应的地方设置为1，与高频区域对应的地方设置为0.123456789101112131415161718192021222324252627282930313233#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#低通滤波 (图形模糊化)import cv2import numpy as npfrom matplotlib import pyplot as pltimg=cv2.imread("psb.jpg",0)dft=cv2.dft(np.float32(img),flags=cv2.DFT_COMPLEX_OUTPUT)dft_shift=np.fft.fftshift(dft)magnitude_spectrum=20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))rows,cols=img.shapecrow,ccol=rows/2,cols/2mask=np.zeros((rows,cols,2),np.uint8)mask[int(crow-30):int(crow+30),int(ccol-30):int(ccol+30)]=1fshift=dft_shift*maskf_ishift=np.fft.ifftshift(fshift)img_back=cv2.idft(f_ishift)img_back=cv2.magnitude(img_back[:,:,0],img_back[:,:,1])plt.subplot(121),plt.imshow(img,cmap='gray')plt.title('Input Image'),plt.xticks([]),plt.yticks([])plt.subplot(122),plt.imshow(img_back,cmap='gray')plt.title('img_back'),plt.xticks([]),plt.yticks([])plt.show() OpenCV中的函数cv2.dft()cv2.idft()比Numpy快，但Numpy函数使用更加用户友好。 模式匹配模式匹配是用来在一幅大图中搜寻模板图像位置的方法。和2D卷积一样，它也是利用模板图像在输入图像(大图)上滑动，并在每一个位置对模板图像和与其对应的输入图像的子区域进行比较。返回结果是一个灰度图像，每一个像素值代表此区域与模板的匹配程度。OpenCV提供了函数cv2.matchTemplate()123456789101112131415161718192021222324252627282930313233343536#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg=cv2.imread("psb.jpg",0)img2=img.copy()template=cv2.imread("psbPart.jpg",0)w,h=template.shape[::-1]methods=['cv2.TM_CCOEFF','cv2.TM_CCOEFF_NORMED','cv2.TM_CCORR','cv2.TM_CCORR_NORMED','cv2.TM_SQDIFF','cv2.TM_SQDIFF_NORMED']for meth in methods: img=img2.copy() method=eval(meth)#eval运算储存在字符串里有效的python表达式 res=cv2.matchTemplate(img,template,method) min_val,max_val,min_loc,max_loc=cv2.minMaxLoc(res) #使用不同的比较方法，对结果的解释不同 if method in[cv2.TM_SQDIFF,cv2.TM_SQDIFF_NORMED]: top_left=min_loc else: top_left=max_loc bottom_right=(top_left[0]+w,top_left[1]+h) cv2.rectangle(img,top_left,bottom_right,255,2) plt.subplot(121),plt.imshow(res,cmap='gray') plt.title('Matching Result'),plt.xticks([]),plt.yticks([]) plt.subplot(122),plt.imshow(img,cmap='gray') plt.title('Detected Point'),plt.xticks([]),plt.yticks([]) plt.suptitle(meth) plt.show() 多对象的模式匹配之前在大图中模版图片只出现了一次，如果模板图片出现了很多次，函数cv2.minMaxLoc()只会给出最大最小值，此时就需要使用阈值了。123456789101112131415161718192021222324#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg_rgb=cv2.imread("psbmul.jpg")img_gray=cv2.cvtColor(img_rgb,cv2.COLOR_BGR2GRAY)template=cv2.imread('psbPart.jpg',0)w,h=template.shape[:2]res=cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)threshold=0.8loc=np.where(res&gt;=threshold)for pt in zip(*loc[::-1]): cv2.rectangle(img_rgb,pt,(pt[0]+w,pt[1]+h),(0,0,255),2) while(1): cv2.imshow('res',img_rgb) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() Hough霍夫直线变换&emsp;&emsp;霍夫变换在检测各种形状的技术中非常流行，如果待检测的形状可以用数学表达式写出来，就可以使用霍夫变换检测它，即使要检测的形状存在一点破坏或者扭曲也可以使用。&emsp;&emsp;下面以使用霍夫变换检测直线为例子说明&emsp;&emsp;一条直线的数学表达式y=mx+c或者r=xcosO+YsinO表示，r表示原点到直线的垂直距离，O是直线的垂线与横轴顺时针方向的夹角。cv2.HoughLines()返回值就是(r,O),r的单位是像素，O的单位是弧度。 第一个参数：二值化图像(所以霍夫变换之前需要二值化或Canny边缘检测) 第二，第三个参数：分别代表r和O的精确度。 第四个参数：阈值，只有累加其中的值高于阈值时才被认为是一条直线。也可看成是能检测到的直线的最短长度(以像素点为单位)12345678910111213141516171819202122232425#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread("psb.jpg")gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)edges=cv2.Canny(gray,50,150,apertureSize=3)minLineLength=100maxLineGap=10lines=cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)for x1,y1,x2,y2 in lines[0]: cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2) while(1): cv2.imshow('edges',edges) cv2.imshow('res',img) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() Hough霍夫圆环变换12345678910111213141516171819202122#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread("psb.jpg",0)img=cv2.medianBlur(img,5)cimg=cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)circles=cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,20,param1=50,param2=30,minRadius=0,maxRadius=0)circles=np.uint16(np.around(circles))for i in circles[0,:]: cv2.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2) cv2.circle(cimg,(i[0],i[1]),2,(0,0,255),3)while(1): cv2.imshow('detected circles',cimg) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() 分水岭算法图像分割1234567891011121314151617181920212223242526272829303132333435#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread("code.jpg")gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)ret,thresh=cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)#noise removalkernel=np.ones((3,3),np.uint8)opening=cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel,iterations=2)#sure background areasure_bg=cv2.dilate(opening,kernel,iterations=3)dist_transform=cv2.distanceTransform(opening,1,5)ret,sure_fg=cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)sure_fg=np.uint8(sure_fg)unknown=cv2.subtract(sure_bg,sure_fg)ret,markers1=cv2.connectedComponents(sure_fg)markers=markers1+1markers[unknown==255]=0markers3=cv2.watershed(img,markers)img[markers3==-1]=[255,0,0]while(1): cv2.imshow('res',img) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() 用GrabCut算法进行交互式前景提取图像特征的提取与描述Harris角点检测特征检测器。 Shi-Tomasi角点检测(适合跟踪的图像特征)特征检测器。 尺度不变特征变换(SIFT)使用SIFT算法进行关键点检测和描述。 加速稳健特征算法(SURF)加速版的SIFT算法。 FAST算法特征检测器BRIEF特征点描述符一种对特征点描述符计算和匹配的快速方法 ORB算法FAST关键点检测和BRIEF关键点描述符的结合体。 Brute-Force特征匹配FLANN匹配器使用特征匹配和单应性查找对象]]></content>
      <categories>
        <category>OpenCV的Python实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenCV的Python实践(3)]]></title>
    <url>%2F2019%2F05%2F18%2FOpenCvPythonPractice-3%2F</url>
    <content type="text"><![CDATA[图像梯度 &emsp;&emsp;图像梯度原理：简单来说就是求导。&emsp;&emsp;OpenCV提供了三种不同的梯度滤波器，或者说高通滤波器：Sobel，Scharr和Laplacian。Sobel和Scharr是求一阶或二阶导数。Scharr是对Sobel（使用小的卷积核求解梯度角度时）的优化，Laplacian是求二阶导数。 Sobel算子和Scharr算子&emsp;&emsp;Sobel算子是高斯平滑与微分操作的结合体，它的抗噪音能力很好。可以设定求导的方向（xorder或yorder）。还可以设定使用的卷积核的大小（ksize），如果ksize=-1，会使用3x3的Scharr滤波器，效果会更好，若速度相同，在使用3x3滤波器时尽量使用Scharr。&emsp;&emsp;3x3的Scharr滤波器卷积核如下： X方向 -3 0 3 -10 0 10 -3 0 3 + Y方向 -3 -10 -3 0 0 0 3 10 3 2.Laplacian算子(拉普拉斯算子)&emsp;&emsp;拉普拉斯算子可以使用二阶导数的形式定义，可假设其离散实现类似于二阶Sobel导数，事实上OpenCV在计算拉普拉斯算子时直接调用Sobel算子。&emsp;&emsp;拉普拉斯滤波器使用的卷积核：123456789101112131415161718192021222324#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#用以上三种滤波器对同一幅图像进行操作，卷积核使用为5x5。import cv2import numpyfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg',0)laplacian = cv2.Laplacian(img,cv2.CV_64F)sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)plt.subplot(2,2,1),plt.imshow(img,cmap='gray')plt.title('original'),plt.xticks([]),plt.yticks([])plt.subplot(2,2,2),plt.imshow(laplacian,cmap='gray')plt.title('laplacian'),plt.xticks([]),plt.yticks([])plt.subplot(2,2,3),plt.imshow(sobelx,cmap='gray')plt.title('Sobel X'),plt.xticks([]),plt.yticks([])plt.subplot(2,2,4),plt.imshow(sobely,cmap='gray')plt.title('Sobel Y'),plt.xticks([]),plt.yticks([])plt.show() 当我们可以通过参数-1来设定输出图像的深度（数据类型）与原图像保持一致，但是我们在代码中使用的却是cv2.CV_64F。这是为什么？想象一下一个从黑到白的边界的导数是正数，而一个从白到黑的边界的导数却是负数。如果原图像的深度是np.int8时，所有的负值都会被截断变成0。换句话就是把边界丢失掉。所以如果这两种边界你都想检测到，最好的办法就是将输出的数据类型设置的更高，比如cv2.CV_16S等，取绝对值然后再把它转回到cv2.CV_8U。 Canny边缘检测原理 噪音去除&emsp;&emsp;由于边缘检测很容易受到噪音影响，所以第一步是使用5x5的高斯滤波器去除噪音。 计算图像梯度&emsp;&emsp;对平滑后的图像使用Sobel算子计算水平方向和竖直方向的一阶导数（图像梯度）（Gx和Gy）。根据得到的这两幅梯度图找到边界的梯度和方向。公式如下：&emsp;&emsp;梯度的方向一般总是与边界垂直。梯度方向被归为四类：垂直，水平，和两条对角线。 非极大值抑制&emsp;&emsp;在获得梯度的方向和大小之后，应该对整幅图想做一个扫描，出去那些非边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯度方向的点中最大的。&emsp;&emsp;现在你得到的是一个包含“窄边界”的二值图像。 滞后阀值&emsp;&emsp;现在要确定那些边界才是真正的边界，需要设置两个阀值：minVal和maxVal。当图像的灰度梯度高于maxVal时被认为是真的边界，那些低于minVal的边界会被抛弃。如果介于两者之间的话，就要看这个点是否与某个被确定为真正边界点相连，如果是，就认为它也是边界点，如果不是就抛弃。OpenCV中的Canny边界检测&emsp;&emsp;cv2.Canny()第一个参数是输入图像，第二和第三个分别是minVal和maxVal。第三个参数设置用来计算图像梯度的Sobel卷积核的大小，默认值为3。最后一个参数是L2gradient，它可以用来设定求梯度大小的方程。如果设为True，就使用我们上面提到过的方程，否则使用方程代替，默认为False12345678910111213141516#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg',0)edges = cv2.Canny(img,100,200)plt.subplot(121),plt.imshow(img,cmap='gray')plt.title('original'),plt.xticks([]),plt.yticks([])plt.subplot(122),plt.imshow(edges,cmap='gray')plt.title('edge'),plt.xticks([]),plt.yticks([])plt.show() 图像金字塔原理&emsp;&emsp;一般情况下，我们要处理是一副具有固定分辨率的图像。但是特别情况下我们需要对同一个图像的不同分辨率的子图像进行处理，如查找图像中的某个目标，如人脸，我们不知道目标在图像中的尺寸大小。这种情况下，我们需要创建一组图像，这些图像是具有不同分辨率的原始图像。我们把这组图像叫做图像金字塔。就是同一图像的不同分辨率的子图集合。我们把最大的图像放在底部，最小的放在顶部，看起来就像一座金字塔。有两类：高斯金字塔和拉普拉斯金字塔。 高斯金字塔&emsp;&emsp;高斯金字塔的顶部是通过将底部图像中的连续的行和列去除得到的。顶部图像中的每个像素值等于下一层图像中5个像素的高斯加权平均值。这样操作一次一个MxN的图像就变成了一个M/2xN/2的图像。所以这幅图像的面积就变为原来图像面积的四分之一。这被称为Octave。连续这样的操作，我们就会得到一个分辨率不断下降的图像金字塔。可以使用函数cv2.pyrDown()和cv2.pyrUp()构建图像金字塔。&emsp;&emsp;cv2.pyrDown从一个高分辨率大尺寸的图像向上构建一个金字塔（尺寸变小，分辨率降低）1234567891011121314151617#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import numpy as npimport cv2img = cv2.imread('psb.jpg')lower_reso = cv2.pyrDown(img)while(1): cv2.imshow('img',img) cv2.imshow('lower_reso',lower_reso) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() &emsp;&emsp;cv2.pyrUp从一个低分辨率小尺寸的图像向上构建一个金字塔（尺寸变大，但分辨率不会增加）12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import numpy as npimport cv2img = cv2.imread('psb.jpg')lower_reso = cv2.pyrDown(img)higher_reso2 = cv2.pyrUp(img)while(1): cv2.imshow('img',img) cv2.imshow('lower_reso',lower_reso) cv2.imshow('higher_reso2',higher_reso2) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() higher_reso2和higher_reso是不同的。因为一旦使用cv2.pyrDown图像的分辨率就会降低，信息就会被丢失。 拉普拉斯金字塔拉普拉斯金字塔可以由高斯金字塔计算得来。公式如下：拉普拉斯金字塔的图像看起来就像是边界图，其中很多像素都是0，常被用在图像压缩中。 使用金字塔进行图像融合&emsp;&emsp;在图像缝合中，由于连接区域图像像素的不连续，整幅图看起来会很差，金字塔就可以实现无缝连接。实现步骤： 读入两幅图 构建各自的高斯金字塔(6层) 根据高斯金字塔计算拉普拉斯金字塔 在拉普拉斯的每一层进行图像融合 根据融合后的图像金字塔重建原始图像&emsp;&emsp;重建原始图像过程：什么是轮廓&emsp;&emsp;轮廓可以简单认为成连续的点（连着边界）连在一起的曲线，具有相同的颜色或者灰度。轮廓在形状分析和物体的检测和识别中很有用。 为了准确，要使用二值化图像。需要进行阀值化处理或者Canny边界检测。 查找轮廓的函数会修改原始图像。如果之后想继续使用原始图像，应该将原始图像储存到其他变量中。 OpenCV中，查找轮廓就像在黑色背景中超白色物体。你应该记住，要找的物体应该是白色而背景应该是黑色。 在二值图像中查找轮廓使用函数cv2.findContours(),有三个参数，第一个是输入图像，第二个是轮廓检索模式，第三个是轮廓近似方法。返回值有三个，第一个是图像，第二个是轮廓，第三个是（轮廓的）层析结构。轮廓（第二个返回值）是一个Python列表，其中储存这图像中所有轮廓。每一个轮廓都是一个Numpy数组，包含对象边界点（x，y）的坐标。绘制轮廓&emsp;&emsp;函数cv2.drawContours()可以被用来绘制轮廓。它可以根据你提供的边界点绘制任何形状。它的第一个参数是原始图像，第二个参数是轮廓，一个python列表，第三个参数是轮廓的索引（在绘制独立轮廓是很有用，当设置为-1时绘制所有轮廓）。接下来的参数是轮廓的颜色和厚度。123456789101112131415161718192021222324#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import numpy as npimport cv2img = cv2.imread('psb.jpg')imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)ret,thresh = cv2.threshold(imgray,127,255,0)contours,hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)#绘制独立轮廓，如第四个轮廓imag = cv2.drawContours(img,contours,-1,(0,255,0),3)#但是大多数时候，下面方法更有用#imag = cv2.drawContours(img,contours,3,(0,255,0),3)while(1): cv2.imshow('img',img) cv2.imshow('imgray',imgray) cv2.imshow('imag',imag) if cv2.waitKey(1) == ord('q'): breakcv2.destroyAllWindows() 轮廓的近似方法&emsp;&emsp;之前提到轮廓是一个形状具有相同灰度值的边界，它会存储形状边界上所有的（x,y）坐标。实际上我们不需要所有的点，当需要直线时，找到两个端点即可。cv2.CHAIN_APPROX_SIMPLE可以实现。它会将轮廓上的冗余点去掉，压缩轮廓，从而节省内存开支。&emsp;&emsp;下面用矩阵来演示，在轮廓列表中的每一个坐标上画一个蓝色圆圈。第一个显示使用cv2.CHAIN_APPROX_NONE的效果，一共734个点，第二个图是使用cv2.CHAIN_APPROX_SIMPLE的结果，只有4个点。 轮廓特征 矩&emsp;&emsp;图像的矩可以帮助我们计算图像的质心，面积等。&emsp;&emsp;函数cv2.moments()会将计算得到的矩以一个字典的形式返回。 1234567891011121314151617#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import numpy as npimport cv2img = cv2.imread('psb.jpg',0)ret,thresh = cv2.threshold(img,127,255,0)contours,hierarchy=cv2.findContours(thresh,1,2)cnt=contours[0]M=cv2.moments(cnt)print(M)#根据这些矩的值，我们可以计算出对象的重心cx=int(M['m10']/M['m00'])cy=int(M['m01']/M['m00']) 轮廓面积&emsp;&emsp;可以使用函数cv2.contourArea()计算得到，也可以用矩（0阶矩），M[‘m00’]。 1area=cv2.contourArea(cnt) 轮廓周长&emsp;&emsp;也被称为弧长。可以使用函数cv2.arcLength()计算得到。这个函数的第二参数可以用来指定对象的形状是闭合的（True），还是打开的（一条曲线）。 1perimeter = cv2.arcLength(cnt,True) 轮廓近似&emsp;&emsp;将轮廓形状近似到另外一种由更少点组成的轮廓形状，新轮廓的点的数目由我们设定的准确度来决定，使用的Douglas-Peucker算法，可以自己Google。假设我们要在一幅图像中查找一个矩形，但是由于图像的种种原因我们不能得到一个完美的矩形，而是一个“坏形状”，现在就可以使用这个函数来近似这个形状，第二个参数是epsilon，它是从原始轮廓到近似轮廓的最大距离，它是一个准确度参数。 12epsilon=0.1*cv2.arcLength(cnt,True)approx = cv2.approxPolyDP(cnt,epsilon,True) 凸包&emsp;&emsp;凸包与轮廓近似相似，但不同，虽然有些情况下它们给出的结果是一样的。函数cv2.convexHull()可以用来检测一个曲线是否具有凸性缺陷，并能纠正缺陷。一般来说，凸性曲线总是凸出来的，至少是平的。如果有地方凹进去了就被叫做凸性缺陷。例如下图中的手，红色曲线显示了手的凸包，凸性缺陷被双箭头标出来了。 1234567hull = cv2.convexHull(points,hull,clockwise,returnPoints)#points 我们要传入的轮廓#hull 输出，通常不需要#clockwise 方向标志，如果设置为True，输出的凸包是顺时针方向的，否则为逆时针方向。#returnPoints默认值为True。它会返回凸包上点的坐标，如果设置为False，就会返回与凸包点对应的轮廓上的点。要获得上图的凸包，可以用下面命令：hull=cv2.convexHull(cnt) 但是如果你想获得凸性缺陷，需要把returnPoints设置为False。以上面矩形为例，首先我们找到他的轮廓从cnt。现在把returnPoints设置为True查找凸包，得到的就是矩形的四个角点。把returnPoints设置为False，得到的是轮廓点的索引。 凸性检测&emsp;&emsp;函数cv2.isContourConvex()可以检测一个曲线是不是凸的。它只能返回True或者False。 1k=cv2.isContourConvex(cnt) 边界矩形&emsp;&emsp;直边界矩形，一个直矩形，没有旋转。不会考虑对象是否旋转。所以边界矩形的面积不是最小的。可以使用函数cv2.boundingRect()查找得到 123#（x,y）为矩形左上角的坐标，（w,h）是矩形的宽和高x,y,w,h=cv2.boundingRect(cnt)img=cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2) 旋转的边界矩形，这个边界矩形是面积最小的，因为它考虑了对象的旋转。用函数cv2.minAreaRect()。返回的是一个Box2D结构，其中包含矩形最上角角点坐标（x，y）矩形的宽和高（w,h）以及旋转角度。但是要绘制这个矩形需要矩形的4个角点，可以通过函数cv2.boxPoints()获得。其中绿色的为直矩形，红色为旋转矩形。 最小外接圆&emsp;&emsp;函数cv2.minEnclosingCircle()可以帮我们找到一个对象的外接圆。它是所有能够包括对象的圆中面积最小的一个。1234(x,y),radius = cv2.minEnclosingCircle(cnt)center = (int(x),int(y))radius = int(radius)img = cv2.circle(img,center,radius,(0,255,0),2) 椭圆拟合&emsp;&emsp;使用函数cv2.ellipse()，返回值其实就是旋转边界矩形的内切圆。12ellipse = cv2.fitEllipse(cnt)img = cv2.ellipse(img,ellipse,(0,255,0),2) 直线拟合&emsp;&emsp;可以根据一组点拟合出一条直线，同样我们也可以为图像中的白色点拟合出一条直线。12345rows,cols = img.shape[:2][vx,vy,x,y]=cv2.fitLine(cnt,cv2.DIST_L2,0,0.01,0.01)lefty=int((x*vy/vx)+y)righty=int(((cols-x)*vy/vx)+y)img = cv2.line(img,(cols-1,righty),(0,lefty),(0,255,0),2) 轮廓的性质 长宽比边界矩形的宽高比 12x,y,w,h=cv2.boundingRect(cnt)aspect_ratio = float(w)/h Extent轮廓面积与边界矩形面积的比 1234area=cv2.contourArea(cnt)x,y,w,h=cv2.boundingRect(cnt)rect_area=w*hextent=float(area)/rect_area Solidity轮廓面积与凸包面积的比 1234area=cv2.contourArea(cnt)hull=cv2.convexHull(cnt)hull_area=cv2.contourArea(hull)solidity=float(area)/hull_area 与轮廓面积相等的圆形的直径 12area=cv2.contourArea(cnt)equi_diameter=np.sqrt(4*area/np.pi) 方向对象的方向，下面的方法还会返回长轴和短轴的长度 1(x,y),(MA,ma),angle=cv2.fitEllipse(cnt) 掩模和像素点有时我们需要构成对象的所有像素点 1234mask=np.zeros(imgray.shate,np.uint8)#这里一定要使用参数-1，绘制填充的轮廓cv2.drawContours(mask,[cnt],0,255,-1)pixelpoints=np.transpose(np.nonzero(mask)) 最大值和最小值及它们的位置可以使用掩模图像得到这些参数 1min_val,max_val,min_loc,max_loc=cv2.minMaxLoc(imgray,mask=mask) 平均颜色及平均灰度同样使用相同的掩模来求得 1mean_val=cv2.mean(im,mask=mask) 9.极点一个对象最上，最下，最左，和最右的点1234leftmost=tuple(cnt[cnt[:,:,0].argmin()[0])rightmost=tuple(cnt[cnt[:,:,0].argmax()[0])topmost=tuple(cnt[cnt[:,:,1].argmin()[0])bottommost=tuple(cnt[cnt[:,:,1].argmax()[0]) 轮廓：更多函数 凸缺陷找到凸缺陷12hull=cv2.convexHull(cnt,returnPoints=False)defects=cv2.convexityDefects(cnt,hull) 它会返回一个数组，其中每一行包含的值是[起点，终点，最远的点，到最远点的近似距离] Point Polygon Test求解图像中的一个点到一个对象轮廓的最短距离。如果点再轮廓的外部，返回值为负，如果在轮廓上，返回值为0，如果在轮廓内部，返回值为正。1dist = cv2.pointPolygonTest(cnt,(50,50),True) 此函数的第三个参数是measureDist。如果设置为True，就会计算最短距离。如果是False，只会判断这个点与轮廓之间的位置关系（返回值为+1,-1,0） 形状匹配函数cv2.matchShape()可以帮我们比较两个形状或者轮廓的相似度，如果返回值越小，匹配越好，它是根据Hu矩来计算的。 轮廓的层次结构 什么是层次结构&emsp;&emsp;通常我们使用函数cv2.findContours 在图片中查找一个对象。有时对象可能位于不同的位置。还有些情况，一个形状在另外一个形状的内部，这种情况下我们称外部的形状为父，内部的形状为子。按照这种方式分类，一幅图像中的所有轮廓之间就建立父子关系。这样我们就可以确定一个轮廓与其他轮廓是怎样连接的，比如它是不是某个轮廓的子轮廓，或者是父轮廓。这种关系就成为组织结构。 opencv中层次结构OpenCV使用一个含有四个元素的数组表示父子关系，【Next，Previous，First_Child，Parent】Next表示同一级组织结构中的下一个轮廓。Previous 示同一级结构中的前一个轮廓。First_Child 示它的第一个子轮廓。Parent 示它的父轮廓。 轮廓检索模式RETR_LIST 从的度来看中应是简单的。它只是提取所有的轮廓而不去创建任何父子关系。换句就是‘’人人平等‘’它们属于同一级组织轮廓。所以在种情况下组织结构数组的第三和第四个数是 -1。但是很明 显Next 和 Previous 有对应的值。RETR_EXTERNAL 如果你择种模式的只会回外的的轮廓，所有的子轮廓会忽略掉。 直方图 直方图原理&emsp;&emsp;直方图是一个简单的表，它给出了一幅图像或一组图像中拥有给定数值的像素数量。例如灰度图像的直方图有265个条目(或称为容器)。0号容器给出值为0的像素个数，1号容器给出值为1的像素个数，依次类推。显然对直方图的所有项求和会得到像素的总数。直方图也可以被归一化，归一化后的所有项之和等于1，在这种情况下，每一项给出的都是拥有特定数值的像素在图像中占的比例。&emsp;&emsp;通过直方图可以对整幅图像的灰度分布有一个整体的了解。直方图的X轴是灰度值（0,255），Y轴是图片中具有同一个灰度值的点的数目。&emsp;&emsp;通过直方图我们可以对图像的对比度，亮度，灰度分布等有一个直观的认识。相关术语： BINS:每个灰度值对应的像素数。如果像素值为0到255，就需要256个数来显示上面的直方图。 DIMS:收集数据的参数数目。 RANGE:要统计的灰度值范围，一般[0,256]. 函数cv2.calcHist可以统计一幅图像的直方图。cv2.calcHist(images,channels,mask,histSize,range[,hist[,accumulate]]) images:原图像(格式uint8或float32),传入函数时应用中括号括起来，如[img] channels:传入函数时应用中括号括起来 mask:掩模图像 histSize:BIN的数目，应用中括号括起来，如[256] ranges:像素范围，通常[0,256] 以灰度格式加载一幅图像，并统计图像的直方图。1234567891011121314151617#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg')hist=cv2.calcHist([img],[0],None,[256],[0,256])#参数中只有mask是没有中括号的while(1): cv2.imshow('hist',hist) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() hist是一个256x1的数组，每一个值代表与次灰度值对应的像素点数目。 使用Numpy统计直方图&emsp;&emsp;Numpy中的np.histogram()可以统计直方图。12345678910111213141516#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg')hist,bins=np.histogram(img.ravel(),256,[0,256])while(1): cv2.imshow('bins',bins) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() matplotlib读取图片显示颜色失真的问题原因是matplotlib的多通道顺序是bgr，跟openCV中的rbg顺序不同。1234567891011121314151617181920212223#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')#重新安排多通道顺序b,g,r = cv2.split(img)img2 = cv2.merge([r, g, b])plt.subplot(121)plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')plt.xticks([])plt.yticks([])plt.subplot(122)plt.imshow(img2, cmap = 'gray', interpolation = 'bicubic')plt.xticks([])plt.yticks([])plt.show() 绘制直方图 使用Matplotlib绘图函数。（简单方法）123456789101112131415161718#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg',0)#plt.hist(img,ravel(),hitsizes,ranges,color=)#img.ravel()将原图像的array数组转成一维的数组#hitsizes 为直方图的灰度级数#ranges为灰度范围[0,255]#color是参数，需要使用color='r'来指定颜色plt.hist(img.ravel(),256,[0,256])plt.show() &emsp;&emsp;分别绘制查看各通道的直方图12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')color=('b','g','r')#对列表或数组既要遍历索引又要遍历元素时#使用内置enumerate更加直接优美#enumerate会将数组或列表组成一个索引序列for i,col in enumerate(color): histr=cv2.calcHist([img],[i],None,[256],[0,256]) plt.plot(histr,color=col) plt.xlim([0,256])plt.show() 使用掩模&emsp;&emsp;要统计图像局部区域的直方图，需要构建一幅掩模图像。&emsp;&emsp;将要统计的部分设置成白色，其余为黑色，就构成了掩模图像。12345678910111213141516171819202122232425#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')#创建掩模图像mask=np.zeros(img.shape[:2],np.uint8)mask[100:200,100:300]=255masked_img=cv2.bitwise_and(img,img,mask=mask)hist_full=cv2.calcHist([img],[0],None,[256],[0,256])hist_mask=cv2.calcHist([img],[0],mask,[256],[0,256])plt.subplot(221),plt.imshow(img,'gray')plt.subplot(222),plt.imshow(mask,'gray')plt.subplot(223),plt.imshow(masked_img,'gray')plt.subplot(224),plt.plot(hist_full),plt.plot(hist_mask)plt.xlim([0,256])plt.show() OpenCV以灰度模式加载彩图1img = cv2.imread('psb.jpg',0) 直方图均衡化&emsp;&emsp;如果图片整体很亮，那所有像素应该都会很高，但是一幅高质量的图像的像素值分布应该很广泛。所以偏亮的直方图(像素偏高)你应该把它的直方图做一个横向拉伸。这就是直方图均衡化，通常能改善图像的对比度。&emsp;&emsp;偏亮的图的直方图大部分在灰度值较高的地方，我们希望直方图分布比较分散，能够涵盖整个x轴，所以需要一个变换函数能把现在的直方图映射到一个广泛分布的直方图中，这就是直方图均衡化需要做的事。&emsp;&emsp;即使是偏暗的图片，经过均衡化之后也能得到相同的结果，直方图均衡化是使所有图片具备相同的亮度条件的参考工具，在很多情况，如脸部识别，训练分类器前，训练集的所有图片都要先进行直方图均衡化达到相同的亮度条件。 OpenCV中的灰度图直方图均衡化cv2.equalizeHist(img)，将要均衡化的原图像(要求是灰度图像)作为参数传入，则返回值即为均衡化后的图像。 1234567891011121314151617181920#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg',0)equ=cv2.equalizeHist(img)#numpy拼接数组#np.vstack():在竖直方向上堆叠#np.hstack():在水平方向上平铺res=np.hstack((img,equ))while(1): cv2.imshow('res',res) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() OpenCV中的彩色图片直方图均衡化 1234567891011121314151617181920212223242526272829303132#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltdef hisEqulColor(img): ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB) channels = cv2.split(ycrcb) print(str(len(channels))) cv2.equalizeHist(channels[0], channels[0]) cv2.merge(channels, ycrcb) cv2.cvtColor(ycrcb, cv2.COLOR_YCR_CB2BGR, img) return imgimg0 = cv2.imread('psb.jpg')#数组的复制img=img0.copy()eq=hisEqulColor(img)#numpy拼接数组#np.vstack():在竖直方向上堆叠#np.hstack():在水平方向上平铺res=np.hstack((img0,eq))while(1): cv2.imshow('res',res) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() 有限对比适应性直方图均衡化&emsp;&emsp;之前的直方图均衡化会改变整个图像的对比度，很多情况这样效果并不好(直方图均衡化改变对比度的原因是因为该图的直方图并不集中在某个区域)。&emsp;&emsp;自适应的直方图均衡化，整幅图被分成很多个小块，称为tiles（OpenCV中tile大小默认8x8）,然后对每一个小块分别直方图均衡化。所以在每一个区域中，各自的直方图会集中在某一个小的区域内(除非噪声干扰)，如果有噪声的话，噪声会被放大，为避免这种情况，要使用对比度限制，对每个小块来说，如果直方图中的bins超过对比度上限的话，就把其中的像素点均匀分散到其他bins中，然后进行直方图均衡化。最后，为去除每一个小块之间人造的边界，再使用双线性差值，对小块进行缝合。 123456789101112131415161718#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#灰度图的自适应直方图均衡化import cv2import numpy as npfrom matplotlib import pyplot as pltimg0 = cv2.imread('psb.jpg',0)clahe=cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))cli=clahe.apply(img0)while(1): cv2.imshow('res',cli) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() 2D直方图&emsp;&emsp; 前面绘制了一维直方图，之所以称为一维，因为只考虑了图像的一个特征：灰度。但在2d直方图中我们要考虑两个图像特征，彩图直方图通常情况下我们需要考虑每个的颜色(Hue)和饱和度(Saturation)。根据这两个特征绘制2D直方图。 OpenCV中的2D直方图绘制彩色直方图，首先需要将图像的颜色空间从BGR转换到HSV.参数做如下修改 channels=[0,1] 因为需要同时处理H和S两个通道 bins=[180,256] H通道为180，S通道为256 range=[0,180,0,256] H取值范围0-180，S取值范围0-256 123456789101112131415161718#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)hist=cv2.calcHist([hsv],[0,1],None,[180,256],[0,180,0,256])while(1): cv2.imshow('hist',hist) if cv2.waitKey() == ord('q'): breakcv2.destroyAllWindows() 12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')b,g,r = cv2.split(img)img2 = cv2.merge([r, g, b])hsv=cv2.cvtColor(img2,cv2.COLOR_BGR2HSV)hist=cv2.calcHist([hsv],[0,1],None,[180,256],[0,180,0,256])plt.imshow(hist,interpolation='nearest')plt.show()]]></content>
      <categories>
        <category>OpenCV的Python实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenCV的Python实践(2)]]></title>
    <url>%2F2019%2F05%2F18%2FOpenCvPythonPractice-2%2F</url>
    <content type="text"><![CDATA[几何变换—扩展缩放 &emsp;&emsp;只是改变图像的尺寸大小，cv2.resize()可以实现这个功能。在缩放时推荐cv2.INTER_AREA，在拓展时推荐cv2.INTER_CUBIC（慢）和cv2.INTER_LINEAR。默认情况下所有改变图像尺寸大小的操作使用的是插值法都是cv2.INTER_LINEAR。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2 img = cv2.imread('psb.jpg')#下面的None本应该是输出图像的尺寸，但是因为后面设置了缩放因子，所以，这里为Noneres = cv2.resize(img,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)#这里直接设置输出图像的尺寸，所以不用设置缩放因子height,width =img.shape[:2]res = cv2.resize(img,(2*width,2*height),interpolation=cv2.INTER_CUBIC)while(1): cv2.imshow('res',res) cv2.imshow('img',img) if cv2.waitKey(1)&amp;0xFF == 27: breakcv2.destroyAllWindows() 几何变换—平移&emsp;&emsp;如果想要沿（x，y）方向移动，移动的距离为（tx,ty）可以以下面方式构建移动矩阵。&emsp;&emsp;使用Numpy数组构建矩阵，数据类型是np.float32，然后传给函数cv2.warpAffine()函数cv2.warpAffine() 的第三个参数的是输出图像的大小，它的格式应该是图像的（宽，高）。应该记住的是图像的宽对应的是列数，高对应的是行数。1234567891011121314151617#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#将图像平移到到点（200,100）处import cv2import numpy as np img=cv2.imread('psb.jpg')rows,cols=img.shape[:2]M= np.float32([[1, 0, 200], [0, 1, 100]])dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('img', dst)k = cv2.waitKey(0)if k == ord('s'): cv2.imwrite('show', dst) cv2.destroyAllWindows() 几何变换—旋转&emsp;&emsp;对一个图像旋转角度θ，需要使用下面的旋转矩阵。&emsp;&emsp;但OpenCV允许在任意地方进行旋转，所以矩阵应该为：&emsp;&emsp;为构建旋转矩阵，OpenCV提供了一个函数cv2.getRotationMatrix2D。1234567891011121314151617181920212223#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2img = cv2.imread('psb.jpg',0)rows,cols=img.shape[:2]#这里的第一个参数为旋转中心，第二个为旋转角度，第三个为旋转后的缩放因子#可以通过设置旋转中心，缩放因子以及窗口大小来防止旋转后超出边界的问题。M=cv2.getRotationMatrix2D((cols/2,rows/2),45,0.6)#第三个参数是输出图像的尺寸中心dst=cv2.warpAffine(img,M,(1*cols,1*rows))while(1): cv2.imshow('img',dst) if cv2.waitKey(1)==27: breakcv2.destroyAllWindows() 几何变换—仿射变换&emsp;&emsp;仿射变换就是图像的线性变换加上平移，用一幅图表示，就是&emsp;&emsp;由image1到image2经过了三个操作 旋转(线性变化) 缩放(线性变化) 平移(向量加)如果没有了第3个平移的操作，那它就是线性变换。&emsp;&emsp;图像的变换要对图像的每一个像素点进行操作，假设其中的一个像素点的坐标是（x,y），我们用矩阵形式表示：我们通常使用2x3矩阵来表示仿射变换:经过仿射变换后的点的矩阵坐标是T，我们已经知道仿射变换就是线性变换加上平移，用矩阵表示的话就是:计算可得，点的坐标经过仿射变换后成为：&emsp;&emsp;观察之前平移，旋转的代码，其中的都有dst = cv2.warpAffine(img, M, (cols, rows))，之所以是平移，是旋转，只是其中的变化矩阵M不同。&emsp;&emsp;在仿射变换中，原图中所有平行线在结果图像中同样平行。为创建这个矩阵，需要从原图像中找到三个点以及他们在输出图像中的位置，然后cv2.getAffineTransForm()会创建一个2X3的矩阵。最后这个矩阵会被传给函数cv2.warpAffine()。123456789101112131415161718192021#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg')rows,cols,ch=img.shape[:3]pts1=np.float32([[0,0],[cols-1,0],[0,rows-1]])pts2=np.float32([[cols*0.2,rows*0.1],[cols*0.9,rows*0.2],[cols*0.1,rows*0.9]])M=cv2.getAffineTransform(pts1, pts2)dst=cv2.warpAffine(img, M, (cols, rows))while(1): cv2.imshow('img',dst) if cv2.waitKey(1)==27: breakcv2.destroyAllWindows() 几何变换—透视变换&emsp;&emsp;对于视角变换，我们需要一个3x3变换矩阵。在变换前后直线还是直线。需要在原图上找到4个点，以及他们在输出图上对应的位置，这四个点中任意三个都不能共线，可以有函数cv2.getPerspectiveTransform()构建，然后这个矩阵传给函数cv2.warpPerspective()。123456789101112131415161718192021#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread('psb.jpg')rows,cols,ch=img.shape[:3]pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])M=cv2.getPerspectiveTransform(pts1,pts2)dst=cv2.warpPerspective(img,M,(cols,rows))while(1): cv2.imshow('img',dst) if cv2.waitKey(1)==27: breakcv2.destroyAllWindows() 旋转和平移都是仿射变换的特殊形式OpenCV中提供warpAffine函数用来实现仿射变换,该函数要求提供用来进行仿射变换的矩阵（2x3），如果不知道该变换矩阵，可以结合两幅图像上三对对应点利用getAffineTransform函数求得仿射变换矩阵。透视变换的本质是将图像投影到一个新的视平面。仿射变换可以理解为透视变换的特殊形式。一幅图像就是一个像素坐标系下的各个带有像素值的坐标点，而透视变换可以理解为就是将一幅图像中的这些坐标点完成了一个坐标转换，将它们的坐标变换到了其他位置，从而实现了变换了图像视角的效果。透视变换可以用透视变换矩阵完成，透视变换矩阵为3x3矩阵:矩阵可以分块来看，T1表示图像线性变换（包括旋转和缩放）、T2表示图像平移，T3用于产生图像透视变换，a33一般为1。透视变换矩阵一般有8个未知数，给定透视变换对应的四对像素点坐标，即可求得透视变换矩阵；反之，给定透视变换矩阵，即可对图像或像素点坐标完成透视变换。仿射变换需要三组点的对应关系，而透视变换需要四组点的对应关系，才可以分别求得仿射变换和透视变换的变换矩阵。 简单阀值&emsp;&emsp;实现函数为cv2.threshold , cv2.adaptiveThreshold等&emsp;&emsp;当像素值高于阀值时，我们给这个像素赋予一个新值（可能是白色），否则我们给它赋予另外一种颜色（也许是黑色）。这个函数就是cv2.threshold()。这个函数的第一个参数就是原图像，原图像应该是灰度图。第二个参数就是用来对像素值进行分类的阀值，第三个参数就是当像素值高于（或者小于）阀值时，应该被赋予新的像素值。OpenCV提供了多种不同的阀值方法，这是有第四个参数来决定的。方法包括 cv2.THRESH_BINARY cv2.THRESH_BINARY_INV cv2.THRESH_TRUNC cv2.THRESH_TOZERO cv2.THRESH_TOZERO_INV1234567891011121314151617181920212223#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb3.jpg')ret , thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)ret , thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)ret , thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)ret , thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)ret , thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)titles = ['original image','Binary','binary-inv','trunc','tozero','tozero-inv']images = [img,thresh1,thresh2,thresh3,thresh4,thresh5]for i in range(6): plt.subplot(2,3,i+1),plt.imshow(images[i],'gray') plt.title(titles[i]) plt.xticks([]),plt.yticks([])plt.show() 自适应阀值&emsp;&emsp;根据图像上的每一个小区域计算与其对应的阀值。因此在同一幅图像上的不同区域采用的是不同的阀值，从而使我们能在亮度不同的情况下得到更好的结果。&emsp;&emsp;这种方法需要我们指定三个参数，返回值只有一个: Adaptive Method :指定计算阀值的方法 cv2.ADAPTIVE_THRESH_MEAN_C:阀值取自相邻区域的平均值 cv2.ADAPTIVE_THRESH_GAUSSIAN_C:阀值取自相邻区域的加权和，权重为一个高斯窗口 Block Size :邻域大小（用来计算阀值的区域大小） C :这就是一个常数，阀值就等于的平均值或者加权平均值减去这个常数。1234567891011121314151617181920212223242526#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb3.jpg',0)#中值滤波img = cv2.medianBlur(img,5)ret , th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)# 11为block size，2为C值th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C , cv2.THRESH_BINARY,11,2 )th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C , cv2.THRESH_BINARY,11,2)titles = ['original image' , 'global thresholding (v=127)','Adaptive mean thresholding', 'adaptive gaussian thresholding']images = [img,th1,th2,th3]for i in range(4): plt.subplot(2,2,i+1),plt.imshow(images[i],'gray') plt.title(titles[i]) plt.xticks([]),plt.yticks([])plt.show() Otsu’s二值化&emsp;&emsp;在使用全局阈值时，随便给了一个数来做阈值，那怎么知道选取的这个数的好坏呢？答案就是不停的尝试。如果是一副双峰图像（简单来说双峰图像是指图像直方图中存在两个峰）呢？我们岂不是应该在两个峰 之间的峰谷选一个值作为阈值？这就是Otsu二值化要做的。简单来说就是对一副双峰图像自动根据其直方图计算出一个阈值。（对于非双峰图像，这种方法得到的结果可能会不理想）。&emsp;&emsp;这里用到到的函数还是 cv2.threshold()，但是需要多传入一个参数 （ﬂag）：cv2.THRESH_OTSU。这时要把阈值设为 0。然后算法会找到最优阈值，这个最优阈值就是返回值 retVal。如果不使用 Otsu 二值化，返回的 retVal 值与设定的阈值相等。1234567891011121314151617181920212223242526272829303132333435#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb3.jpg',0)ret1,th1=cv2.threshold(img,127,255,cv2.THRESH_BINARY)ret2,th2=cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)#(5,5)为高斯核的大小，0为标准差blur= cv2.GaussianBlur(img,(5,5),0)#阀值一定要设为0ret3,th3=cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)images=[img,0,th1, img,0,th2, img,0,th3]titles =['original noisy image','histogram','global thresholding(v=127)', 'original noisy image','histogram',"otsu's thresholding", 'gaussian giltered image','histogram',"otus's thresholding"]#这里使用了pyplot中画直方图的方法，plt.hist要注意的是他的参数是一维数组#所以这里使用了（numpy）ravel方法，将多维数组转换成一维，也可以使用flatten方法for i in range(3): plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray') plt.title(titles[i*3]),plt.xticks([]),plt.yticks([]) plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256) plt.title(titles[i*3+1]),plt.xticks([]),plt.yticks([]) plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray') plt.title(titles[i*3+2]),plt.xticks([]),plt.yticks([]) plt.show() 2D卷积同一维信号一样，可以对2D图像实施低通滤波（LPF）和高通滤波（HPF）。LPF用于去除噪音，模糊图像，HPF用于找到图像的边缘。OpenCV提供的函数cv.filter2D()可以对一幅图像进行卷积操作。练习一幅图像使用平均滤波器。举例下面是一个5X5的平均滤波器核：操作如下，将核放在图像的一个像素A上，求与核对应的图像上25（5x5）个像素的和，再取平均数，用这个平均数代替像素A的值。重复以上操作直到将图像的每一个像素值都更新一遍。1234567891011121314151617181920212223242526272829#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')kernel = np.ones((5,5),np.float32)/25#cv.Filter2D(src, dst, kernel, anchor=(-1, -1))#ddepth –desired depth of the destination image;#if it is negative, it will be the same as src.depth();#the following combinations of src.depth() and ddepth are supported:#src.depth() = CV_8U, ddepth = -1/CV_16S/CV_32F/CV_64F#src.depth() = CV_16U/CV_16S, ddepth = -1/CV_32F/CV_64F#src.depth() = CV_32F, ddepth = -1/CV_32F/CV_64F#src.depth() = CV_64F, ddepth = -1/CV_64F#when ddepth=-1, the output image will have the same depth as the source.dst = cv2.filter2D(img,-1,kernel)plt.subplot(121),plt.imshow(img),plt.title('original')plt.xticks([]),plt.yticks([])plt.subplot(122),plt.imshow(dst),plt.title('averaging')plt.xticks([]),plt.yticks([])plt.show() 平均这是由一个归一化卷积框完成的，他只是用卷积框覆盖区域所有像素的平均值来代替中心元素。可以使用cv2.blur()和cv2.boxFilter()来实现， 我们需要设定卷积框的宽和高。同样是一个矩阵。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')blur = cv2.blur(img,(5,5))while(1): cv2.imshow('image',img) cv2.imshow('blur',blur) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 高斯模糊&emsp;&emsp;现在把卷积核换成高斯核，简单的说方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包，原来的求平均数变成求加权平均数，权就是方框里的值。实现的函数是cv2.GaussianBlur()。需要指定高斯核的宽和高（必须是奇数），以及高斯函数沿X,Y方向的标准差。如果我们只指定了X方向的标准差，Y方向也会取相同值，如果两个标准差都是0.那么函数会根据核函数的大小自己计算，高斯滤波可以有效的从图像中去除高斯噪音。&emsp;&emsp;也可以使用cv2.getGaussianKernel()自己构建一个高斯核。&emsp;&emsp;如果要使用高斯模糊的话，上边的代码应改成：1234567891011121314151617181920#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('psb.jpg')# 0是指根据窗口大小（5,5）来计算高斯函数标准差blur = cv2.GaussianBlur(img,(5,5),0)while(1): cv2.imshow('image',img) cv2.imshow('blur',blur) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 中值模糊就是用与卷积框对应像素的中值来替代中心像素的值，这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围或者本身的值来取代他，他能有效去除噪声。卷积核的大小也应该是一个奇数。需要给原始图像加上50%的噪声，然后用中值模糊。123456789101112131415161718#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg')median = cv2.medianBlur(img,5)while(1): cv2.imshow('image',img) cv2.imshow('blur',median) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 双边滤波函数cv2.bilateralFilter()能在保持边界清晰的情况下有效的去除噪音，但比较慢。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度），所以这种方法不会考虑一个像素是否位于边界，因此边界也会被模糊掉。双边滤波在同时使用空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以能保证边界不会被模糊，因此边界处的灰度值变化比较大。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg')# 9 邻域直径，两个 75 分别是空间高斯函数标准差，灰度值相似性高斯函数标准差 blur = cv2.bilateralFilter(img,9,75,75)while(1): cv2.imshow('image',img) cv2.imshow('blur',blur) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–腐蚀&emsp;&emsp;形态学转换原理：一般情况下对二值化图像进行操作。需要两个参数，一个是原始图像，第二个被称为结构化元素或者核，它是用来决定操作的性质的。基本操作为腐蚀和膨胀，他们的变体构成了开运算，闭运算，梯度等。常用函数cv2.erode(),cv2.dilate(),cv2.morphotogyEx()。&emsp;&emsp;腐蚀：把前景物体的边界腐蚀掉，但是前景仍然是白色的。卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是1，那么中心元素就保持原来的像素值，否则就变为零。根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪音很有用，也可以用来断开两个连在一块的物体。123456789101112131415161718#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)erosion = cv2.erode(img,kernel,iterations=1)while(1): cv2.imshow('image',img) cv2.imshow('erosion',erosion) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–膨胀&emsp;&emsp;与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是1，中心元素的像素值就是1。所以这个操作会增加图像中白色区域（前景）。一般在去噪音时先腐蚀再膨胀，因为腐蚀再去掉白噪音的同时，也会使前景对象变小，所以我们再膨胀。这时噪音已经被去除，不会再回来了，但是前景还在并会增加，膨胀也可以用来连接两个分开的物体。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)dilation = cv2.dilate(img,kernel,iterations=1)while(1): cv2.imshow('image',img) cv2.imshow('dilation',dilation) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–开运算先进行腐蚀再进行膨胀就叫做开运算。被用来去除噪音，函数可以使用cv2.morphologyEx()12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)opening = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)while(1): cv2.imshow('image',img) cv2.imshow('opening',opening) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–闭运算先膨胀再腐蚀。被用来填充前景物体中的小洞，或者前景上的小黑点。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)while(1): cv2.imshow('image',img) cv2.imshow('closing',closing) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–梯度其实就是一幅图像膨胀与腐蚀的差别。结果看上去就像前景物体的轮廓。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)gradient = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)while(1): cv2.imshow('image',img) cv2.imshow('gradient',gradient) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–礼帽原始图像与进行开运算之后得到的图像的差。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)tophat = cv2.morphologyEx(img,cv2.MORPH_TOPHAT,kernel)while(1): cv2.imshow('image',img) cv2.imshow('tophat',tophat) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows() 形态学–黑帽进行闭运算之后得到的图像与原始图像的差。12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg = cv2.imread('psb.jpg',0)kernel = np.ones((5,5),np.uint8)blackhat = cv2.morphologyEx(img,cv2.MORPH_BLACKHAT,kernel)while(1): cv2.imshow('image',img) cv2.imshow('blackhat',blackhat) k=cv2.waitKey(1) if k == ord('q'):#按q键退出 breakcv2.destroyAllWindows()]]></content>
      <categories>
        <category>OpenCV的Python实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenCV的Python实践(1)]]></title>
    <url>%2F2019%2F05%2F16%2FOpenCvPythonPractice-1%2F</url>
    <content type="text"><![CDATA[升级pip window的cmd模式下查询当前pip版本1python -m pip show pip window的cmd模式下升级pip1python -m pip install --upgrade pip &emsp;&emsp;安装cv2的时候出现”Requirement already satisfied”的问题无法使用python -m pip install opencv-python自动安装，可能是因为我的python版本经常换来换去的原因。通过指定安装路径解决，启动自动安装。1python -m pip install --target=D:\Python27_13\Lib\site-packages opencv-python &emsp;&emsp;好吧，可能因为网络原因，我的网是真的慢，安装到一半还是失败，但是获取了相关whl的信息，我直接去下载这个opencv_python-4.1.0.25-cp36-cp36m-win32.whl来手动安装。用迅雷下载这个25兆的文件用了将近5分钟。–upgrade安装时强制替换老版本123python -m pip install --upgrade --target=D:\Python27_13\Lib\site-packages D:\numpy-1.16.3-cp36-cp36m-win32.whlpython -m pip install --upgrade --target=D:\Python27_13\Lib\site-packages D:\opencv_python-4.1.0.25-cp36-cp36m-win32.whlpython -m pip install --upgrade --target=D:\Python27_13\Lib\site-packages D:\matplotlib-3.0.3-cp36-cp36m-win32.whl 环境配置成功 显示保存图片12345678910111213141516171819202122232425262728#!D:\Python34\python.exe# -*- coding: utf-8 -*-#python3.6.8#显示保存图片import cv2 import numpy as npimport matplotlib # python -m pip install matplotlib-3.0.3-cp36-cp36m-win32.whl#print("cv2版本"+cv2.__version__)#print(np.version.version)#print(matplotlib.__version__)#读取图片img=cv2.imread('arterialImg.png',cv2.IMREAD_GRAYSCALE) img2=cv2.imread('arterialImg.png',cv2.IMREAD_COLOR) #cv2.IMREAD_COLOR 彩色模式忽略透明度，cv2.IMREAD_GRAYSCALE 灰度模式#显示图片cv2.imshow('image',img)cv2.imshow('image2',img2)k=cv2.waitKey(0) #0毫秒内无限等待键盘输入，检测键是否按下if k==27: cv2.destroyAllWindows() #ESC按下elif k==ord('s'): #print("保存图片") #cv2.imwrite("mess.jpg",img) cv2.destroyAllWindows()cv2.destroyAllWindows() print("结束") 使用MatplotlibMatplotlib是python的一个绘图库，包含各种各样的绘图方法。 123456789101112131415161718#!D:\Python34\python.exe# -*- coding: utf-8 -*-#python3.6.8#使用Matplotlibimport cv2 import numpy as npfrom matplotlib import pyplot as pltfrom matplotlib.font_manager import FontPropertiesfont_set=FontProperties(fname=r"c:\windows\fonts\simsun.ttc",size=12)img=cv2.imread('arterialImg.png',cv2.IMREAD_COLOR) plt.imshow(img,cmap='gray',interpolation='bicubic')plt.xlabel(u'年份',fontproperties=font_set)plt.ylabel(u'产量',fontproperties=font_set)plt.legend(prop=font_set,loc='best')plt.title("裤子",fontproperties=font_set)plt.show() 使用摄像头捕获视频123456789101112131415161718#!D:\Python34\python.exe# -*- coding: utf-8 -*-#python3.6.8#使用摄像头捕获视频import cv2 import numpy as npcap=cv2.VideoCapture(0)while(True): ret,frame=cap.read() gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) cv2.imshow('frame',gray) if cv2.waitKey(1)&amp; 0xFF == ord('q'): breakcap.release()cv2.destroyAllWindows() &emsp;&emsp;cap.isOpened()可检查摄像头设备是否初始化，如果返回True则没问题，否则要使用cap.open()&emsp;&emsp;cap.get(propid)可获取视频一些参数信息，propid于0–18之间,如cap.get(3)和cap.get(4)可查看每帧宽和高&emsp;&emsp;cap.set(propid,value)可修改视频属性，如cap.set(3,320)将视频宽度设置为320 从文件中播放视频12345678910111213141516171819#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#从文件中播放视频import cv2import numpy as npcap = cv2.VideoCapture("../JustTheWayYouAre.mp4")while(1): #获取一帧图像 ret, frame = cap.read() #显示一帧图像 cv2.imshow("capture", frame) if cv2.waitKey(25) &amp; 0xFF == ord('q'): breakcap.release()cv2.destroyAllWindows() #cv2.waitKey(25) 代表一帧25毫秒，这可以控制播放速度 保存视频&emsp;&emsp;OpenCV是计算机视觉库，可以把图片序列保存成视频(也是基于vfw和ffmpeg的)，但它本身并不是视频编码解码器，只支持avi的格式，而且生成的视频文件不能大于2GB，不能添加音频。如果想突破这些限制，还是得用ffMpeg。&emsp;&emsp;捕获视频，并对每一帧进行加工后想要保存这个视频。&emsp;&emsp;保存视频需要创建一个VideoWriter对象，确定输出文件的名字，指定FourCC编码，帧大小，播放频率和isColor标签。&emsp;&emsp;有一个比较坑的地方，opencv修改后保存视频的帧大小宽高必须与原始视频保持一致才行。1234567891011121314151617181920212223242526272829#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#打开一个本地视频，将每帧图像翻转后保存为另一个视频。import cv2import numpy as npcap = cv2.VideoCapture("../JustTheWayYouAre.mp4")frame_width = int(cap.get(3))frame_height = int(cap.get(4))#需要去http://www.fourcc.org/downloads/divx-912-7/start下载DIVX编码器fourcc = cv2.VideoWriter_fourcc(*'XVID')out = cv2.VideoWriter('output.avi',fourcc, 20.0, (frame_width,frame_height))while(cap.isOpened()): ret, frame = cap.read() if ret==True: frame = cv2.flip(frame,0) out.write(frame) cv2.imshow('frame',frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break else: break cap.release()out.release()cv2.destroyAllWindows() 线,矩形,圆,椭圆,多边形,添加文字需要使用这些函数cv2.line(),cv2.rectangle(),cv2.circle(),cv2.ellipse(),cv2.putText()上面函数都需要设置的共同参数： img：想要绘制图形的那张图 color：形状的颜色，rgb需要传入一个元组，灰度图只需传入灰度值。 thickness：线条粗细。默认为1。如果一个闭合图形设置为-1，该图形被填充。 linetype：线条类型，8连通、抗锯齿等。(并不是指线型是实线、虚线还是点画线，这个参数实际用途是改变线的产生算法)，默认8连通，cv2.LINE_AA为抗锯齿，使线条看起来平滑。 &emsp;&emsp;画线，需要指定线的起点和终点。&emsp;&emsp;画矩形，需要指定左上角顶点和右下角顶点。&emsp;&emsp;画圆，需要指定圆形中心点坐标和半径大小。&emsp;&emsp;画椭圆，需要指定椭圆的中心点坐标、长轴和短轴长度、椭圆沿逆时针旋转的角度，椭圆弧沿顺时针方向起始角度和结束角度(0-360代表整个椭圆)。&emsp;&emsp;画多边形，需要指定每个顶点的坐标。cv2.polylines()可用来画很多线，只需要将要画的线放在一个列表里传给函数即可。每条线被独立绘制，这比cv2.line()一条一条绘制要快一些。&emsp;&emsp;在图片上添加文字，需要设置下列参数：要绘制文字、要绘制的位置、字体类型(通过查看cv2.putText()的文档找到支持字体)、字体的大小、文字的一般属性，如颜色、粗细、线条类型等，为美观一般linetype=cv2.LINE_AA。&emsp;&emsp;所有绘图函数返回值都是None，所以img1=cv2.line(img,(0,0),(511,511),(255,0,0),5)是错误的。12345678910111213141516171819202122232425262728#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#线,矩形,圆,椭圆,多边形,添加文字import cv2import numpy as npimg=np.zeros((512,512,3),np.uint8)#画线cv2.line(img,(0,0),(511,511),(255,0,0),5)#图片上添加文字font=cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2)#画矩形cv2.rectangle(img,(384,0),(510,128),(0,255,0),3)#画圆cv2.circle(img,(447,63), 63, (0,0,255), -1)#画椭圆cv2.ellipse(img,(256,256),(100,50),30,0,360,255,3)#画多边形pts=np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)pts=pts.reshape((-1,1,2))cv2.polylines(img,[pts],True,(0,0,255),3)#如果去掉中括号，只是画四个点。如果第三个参数为False，多边形不闭合首尾不相连，cv2.imshow('opencv',img)cv2.waitKey(0)cv2.destroyAllWindows() 鼠标回调事件1234567891011121314151617181920212223#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#鼠标回调事件import cv2import numpy as npdef draw_circle(event,x,y,flags,param): if event==cv2.EVENT_LBUTTONDBLCLK: cv2.circle(img,(x,y),100,(255,0,0),-1) img=np.zeros((512,512,3),np.uint8)cv2.namedWindow('image')cv2.setMouseCallback('image',draw_circle)while(1): cv2.imshow('image',img) if cv2.waitKey(20)&amp;0xFF==27: # esc退出 breakcv2.destroyAllWindows() 按下拖拽鼠标，mode为true绘制矩形，为False绘制曲线，按M切换12345678910111213141516171819202122232425262728293031323334353637#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npdrawing=Falsemode=Trueix,iy=-1,-1def draw_circle(event,x,y,flags,param): global ix,iy,drawing,mode if event==cv2.EVENT_LBUTTONDOWN: drawing=True ix,iy=x,y elif event==cv2.EVENT_MOUSEMOVE and flags==cv2.EVENT_FLAG_LBUTTON: if drawing==True: if mode==True: cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1) else: cv2.circle(img,(x,y),3,(0,0,255),-1) elif event==cv2.EVENT_LBUTTONUP: drawing==Falseimg=np.zeros((512,512,3),np.uint8)cv2.namedWindow('image')cv2.setMouseCallback('image',draw_circle)while(1): cv2.imshow('image',img) k=cv2.waitKey(1)&amp;0xFF if k==ord('m'): mode=not mode elif cv2.waitKey(20)&amp;0xFF==27: # esc退出 breakcv2.destroyAllWindows() 滑动条&emsp;&emsp;通过调节滑动条设定画板颜色。&emsp;&emsp;cv2.getTrackbarPos()的参数分别为滑动条名字、滑动条被放置窗口的名字、滑动条默认位置、滑动条最大值、回调函数。每次滑动条滑动都会调用回调函数，回调函数的默认参数就是滑动条的位置。12345678910111213141516171819202122232425262728293031323334353637#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npdrawing=Falsemode=Trueix,iy=-1,-1def nothing(x): passimg=np.zeros((512,512,3),np.uint8)cv2.namedWindow('image')cv2.createTrackbar('R','image',0,255,nothing)cv2.createTrackbar('G','image',0,255,nothing)cv2.createTrackbar('B','image',0,255,nothing)switch='0:off\n1:on'cv2.createTrackbar(switch,'image',0,1,nothing)while(1): cv2.imshow('image',img) k=cv2.waitKey(1)&amp;0xFF if k==27: #esc退出 break r=cv2.getTrackbarPos('R','image') g=cv2.getTrackbarPos('G','image') b=cv2.getTrackbarPos('B','image') s=cv2.getTrackbarPos(switch,'image') if s==0: img[:]=0 else: img[:]=[b,g,r]cv2.destroyAllWindows() 获取并修改像素值&emsp;&emsp;cv2.imread()读取的图片默认情况下为彩图（三通道图片），所以，在定位到对应(x,y)像素点上的时候，得到的就是三维向量。numpy的操作基于性能考虑，能用矩阵运算就不用循环。1234567891011121314151617181920#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread("psb.jpg")print(img.shape) #返回图像的属性，包括(行，列，通道数)print(img.size) #图像的像素数目print(img.dtype) #图像的数据类型p=img[100,100] #获取某点属性print(p)px=img.item(100,100,0) py=img.item(100,100,1) pz=img.item(100,100,2) print(str(px)+' '+str(py)+" "+str(pz)) #分别获取某点的rgb各值 img.itemset((100,100,2),138) #设置某分量的值pz=img.item(100,100,2)print(str(pz)) 图像ROI&emsp;&emsp;ROI全称Region Of Internet，感兴趣的区域，就是从图像中选择一个图像区域。&emsp;&emsp;下面代码将一块感兴趣的区域，复制到了另一个地方，或者单独提取出来。1234567891011121314151617#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread("psb.jpg")source=img[280:340,330:390]img[273:333,100:160]=source #感兴趣的区域复制到了另一个地方cv2.imshow('image',img)cv2.imshow('dandu',source) #感兴趣的区域单独提取出来k=cv2.waitKey(0) #0毫秒内无限等待键盘输入，检测键是否按下if k==27: cv2.destroyAllWindows() #ESC按下cv2.destroyAllWindows() 拆分通道及合并通道v2.split函数分离得到各个通道的灰度值(单通道图像)。cv2.merge函数是合并单通道成多通道（不能合并多个多通道图像）。12345678910111213141516171819202122232425262728#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npimg=cv2.imread("psb.jpg")b,g,r=cv2.split(img)print("img shape "+str(img.shape))print("r shape "+str(r.shape))cv2.imshow('r ',r)cv2.imshow('g ',g)cv2.imshow('b ',b)#生成一个值为0的单通道数组zeros = np.zeros(img.shape[:2], dtype = "uint8")# 分别扩展B、G、R成为三通道。另外两个通道用上面的值为0的数组填充cv2.imshow("Blue", cv2.merge([b, zeros, zeros]))cv2.imshow("Green", cv2.merge([zeros, g, zeros]))cv2.imshow("Red", cv2.merge([zeros, zeros, r]))img[:,:,2]=0#所有像素的红通道值为0 BGRcv2.imshow("Blue+Green", img)img[:,:,1]=0#所有像素的绿通道值为0 前两个选所有像素，最后一个选通道img[:,:,0]=0#所有像素的蓝通道值为0 k=cv2.waitKey(0) if k==27: cv2.destroyAllWindows() #ESC按下cv2.destroyAllWindows() 图像加法使用cv2.add()将两幅图像进行加法运算，也可以直接使用numpy，res=img1+img2.两幅图像的大小，类型必须一致，或者第二个图像可以是一个简单的标量值。openCV的加法是一种饱和操作，而numpy的加法是一种模操作。12345678910111213#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as np x=np.uint8([250])y=np.uint8([10])print(cv2.add(x,y))#250+10=260&gt;=255#结果为[[255]]print (x+y)#250+10=260%255=4#结果为[4] 图像混合这也是加法，不同的是两幅图像的权重不同，这会给人一种混合或者透明的感觉。图像混合的计算公式如下：g(x) = (1−α)f0(x)+αf1(x)通过修改α的值（0~1）,可以实现很酷的混合。例：将两幅图像混合，第一幅权重为0.7.第二幅权重为0.3。函数cv2.addWeighed()可以按下面的公式对图片进行混合。dst = α·img1 + β·img2+γ 这里γ的取值为0.123456789101112131415#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as np img1=cv2.imread('psb.jpg')img2=cv2.imread('psb3.jpg')dst = cv2.addWeighted(img1,0.7,img2,0.3,0)cv2.imshow('dst',dst)cv2.waitKey(0)cv2.destroyAllWindows() 123456789101112131415161718192021222324252627282930#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as np def nothing(x): pass img1 = cv2.imread('psb.jpg')img2 = cv2.imread('psb3.jpg')#创建一个黑色背景的窗口img = np.zeros((400,400,3), np.uint8)cv2.namedWindow('image') cv2.createTrackbar('a','image',0,100,nothing) while(1): cv2.imshow('image',img) k = cv2.waitKey(1) &amp; 0xFF if k == 27: break r = cv2.getTrackbarPos('a','image') r=float(r)/100.0 img=cv2.addWeighted(img1,r,img2,1.0-r,0)cv2.destroyAllWindows() 阈值二值化和位运算&emsp;&emsp;图像的二值化，就是将图像上的像素点的灰度值设置为0或255，也就是将整个图像呈现出明显的只有黑和白的视觉效果。&emsp;&emsp;一幅图像包括目标物体、背景还有噪声，要想从多值的数字图像中直接提取出目标物体，常用的方法就是设定一个阈值T，用T将图像的数据分成两部分：大于T的像素群和小于T的像素群。这是研究灰度变换的最特殊的方法，称为图像的二值化（Binarization）。&emsp;&emsp;位运算操作有and, or, not, xor。在提取部分图像选择非矩形区域roi时，位运算操作十分有用。&emsp;&emsp;把opencv的标志放到另外一副图像上，如果使用加法，颜色会改变，如果使用混合，会变成透明，如果是矩形区域，可以使用roi方法，不是矩形时，用位运算实现。12345678910111213141516171819202122232425262728293031#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as np baidu_logo = cv2.imread('baidu.png')target_img=cv2.imread('target.jpg')#图片相加需要有相同的宽和高，所以先构建一个新的图片baidu_resize，大小和目的图片相同baidu_resize = np.ones(target_img.shape,np.uint8)baidu_resize =baidu_resize *255 # 得到白色背景#baidu_resize =baidu_resize *0 # 得到黑色色背景#把baidu_logo图像放入生成的指定长宽大小的图像里baidu_resize[0:baidu_logo.shape[0], 0:baidu_logo.shape[1]] = baidu_logo#得到灰度图baidu_logo_gray = cv2.cvtColor(baidu_resize, cv2.COLOR_BGR2GRAY)#阈值二值化，灰度值大于200的像素点位置赋值255，其他像素点位置赋值0ret, mask = cv2.threshold(baidu_logo_gray, 200, 255, cv2.THRESH_BINARY) #取反操作，mask中255的像素点值变为0， 值为0的像素点新值为255mask_inv = cv2.bitwise_not(mask) #对图像应用maskbaidu_logo_fg = cv2.bitwise_and(baidu_resize, baidu_resize, mask = mask_inv)target_img_bg = cv2.bitwise_and(target_img, target_img, mask = mask)#图像相加融合，得到最终结果added_img = cv2.add(baidu_logo_fg, target_img_bg)cv2.imshow('final',added_img)cv2.waitKey(0)cv2.destroyAllWindows() 图像的运算&emsp;&emsp;图像的基本运算有很多种，比如两幅图像可以相加、相减、相乘、相除、位运算、平方根、对数、绝对值等；图像也可以放大、缩小、旋转，还可以截取其中的一部分作为ROI（感兴趣区域）进行操作，各个颜色通道还可以分别提取及对各个颜色通道进行各种运算操作。总之，对于图像可以进行的基本运算非常的多。&emsp;&emsp;基础数学运算应用于图像像素处理：1234567891011void add(InputArray src1, InputArray src2, OutputArray dst,InputArray mask=noArray(), int dtype=-1);//dst = src1 + src2void subtract(InputArray src1, InputArray src2, OutputArray dst,InputArray mask=noArray(), int dtype=-1);//dst = src1 - src2void multiply(InputArray src1, InputArray src2,OutputArray dst, double scale=1, int dtype=-1);//dst = scale*src1*src2void divide(InputArray src1, InputArray src2, OutputArray dst,double scale=1, int dtype=-1);//dst = scale*src1/src2void divide(double scale, InputArray src2,OutputArray dst, int dtype=-1);//dst = scale/src2void scaleAdd(InputArray src1, double alpha, InputArray src2, OutputArray dst);//dst = alpha*src1 + src2void addWeighted(InputArray src1, double alpha, InputArray src2,double beta, double gamma, OutputArray dst, int dtype=-1);//dst = alpha*src1 + beta*src2 + gammavoid sqrt(InputArray src, OutputArray dst);//计算每个矩阵元素的平方根void pow(InputArray src, double power, OutputArray dst);//src的power次幂void exp(InputArray src, OutputArray dst);//dst = e**src（**表示指数的意思）void log(InputArray src, OutputArray dst);//dst = log(abs(src)) &emsp;&emsp;二进制数据的与、或、非、异或操作应用于图像像素处理：1234void bitwise_and(InputArray src1, InputArray src2,OutputArray dst, InputArray mask=noArray());//dst = src1 &amp; src2void bitwise_or(InputArray src1, InputArray src2,OutputArray dst, InputArray mask=noArray());//dst = src1 | src2void bitwise_xor(InputArray src1, InputArray src2,OutputArray dst, InputArray mask=noArray());//dst = src1 ^ src2void bitwise_not(InputArray src, OutputArray dst,InputArray mask=noArray());//dst = ~src 使用OpenCV检测程序效率cv2.getTickCount函数返回从参考点到这个函数被执行的时钟数。在一个函数执行前后都调用它，可以得到这个函数的执行时间。cv2.getTickFrequency返回时钟频率，或者说每秒钟的时钟数。 1234567891011121314151617#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8#窗口大小不同（5,7,9）的核函数来做中值滤波，查看一个函数运行了多少秒import cv2import numpy as np img1 = cv2.imread('psb.jpg')e1 = cv2.getTickCount() #开始计时for i in range(5,49,2): img1 = cv2.medianBlur(img1,i)e2 = cv2.getTickCount() #结束计时time = (e2-e1)/cv2.getTickFrequency()print(time) #中间过程耗时 OpenCV的默认优化cv2.useOptimized()来查看优化是否被开启，cv2.setUesOptimized()来开启优化。1234567891011121314151617181920212223242526272829303132#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2import numpy as npcv2.setUseOptimized(True)print(cv2.useOptimized()) img1 = cv2.imread('psb.jpg')e1 = cv2.getTickCount()for i in range(5,49,2): img1 = cv2.medianBlur(img1,i)e2 = cv2.getTickCount()time = (e2-e1)/cv2.getTickFrequency()print("优化过的耗时："+str(time))cv2.setUseOptimized(False)img1 = cv2.imread('psb.jpg')e1 = cv2.getTickCount()for i in range(5,49,2): img1 = cv2.medianBlur(img1,i)e2 = cv2.getTickCount()time = (e2-e1)/cv2.getTickFrequency()print("取消优化的耗时："+str(time))cv2.setUseOptimized(True)#取消优化后的耗时更短。。。 转换颜色空间&emsp;&emsp;在OpenCV中有超过150种进行颜色空间转换的方法。但是你以后就会发现我们经常用到的也就两种：BGR↔Gray 和 BGR↔HSV。&emsp;&emsp;我们用到的函数是cv2.cvtColor(input_imageﬂag)，其中ﬂag就是转换类型。&emsp;&emsp;对于BGR↔Gray的转换，我们使用的ﬂag就是cv2.COLOR_BGR2GRAY。&emsp;&emsp;同样对于BGR↔HSV的转换我们用的ﬂag就是cv2.COLOR_BGR2HSV。&emsp;&emsp;得到所有可用的颜色空间flag123456789#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2 for i in dir(cv2): if i.startswith('COLOR_'): print(i) &emsp;&emsp;在OpenCV的HSV格式中，H（色彩/色度）的取值范围是[0，179]，S（饱和度）的取值范围[0，255]，V（亮度）的取值范围[0，255]。但是不同的软件使用的值可能不同。所以当你拿OpenCV的HSV值与其他软件的HSV值对比时，一定要记得归一化。 物体跟踪现在我们知怎样将一幅图像从BGR换到HSV了，我们可以利用这点来提取带有某个特定色的物体。在HSV颜色空间中要比在BGR空间中更容易表示一个特定颜色。在我们的程序中，我们提取的是一个蓝色的物体。以下就是我们做的几步： 从视频中获取每一帧图像 将图像转换到HSV空间 设置HSV阈值到蓝色范围 获取蓝色物体123456789101112131415161718192021222324252627282930#!D:\Python27_13\python.exe# -*- coding: utf-8 -*-#python3.6.8import cv2 import numpy as npcap = cv2.VideoCapture(0)while(1): #获取每一帧 ret,frame = cap.read() #转换到HSV hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV) #设定蓝色的阀值 lower_blue = np.array([110,50,50]) upper_blue = np.array([130,255,255]) #根据阀值构建掩模 mask = cv2.inRange(hsv,lower_blue,upper_blue) #对原图和掩模进行位运算 res = cv2.bitwise_and(frame,frame,mask=mask) #显示图像 cv2.imshow('frame',frame) cv2.imshow('mask',mask) cv2.imshow('res',res) k = cv2.waitKey(5)&amp;0xFF if k == 27: break#关闭窗口cv2.destroyAllWindows()]]></content>
      <categories>
        <category>OpenCV的Python实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MarkDown基础语法]]></title>
    <url>%2F2019%2F05%2F15%2FfirstBlog%2F</url>
    <content type="text"><![CDATA[标题Markdown支持6种级别的标题，对应html标签h1~h6123456# h1## h2### h3#### h4##### h5###### h6 段落及区块引用Markdown其实就是一种易于编写的普通文本，只不过加入了部分渲染文本的标签而已。其最终依然会转换为html标签，因此使用Markdown分段非常简单，前后至少保留一个空行即可。 另外一个比较常见的需求就是，我们可能希望对某段文字进行强调处理。Markdown提供了一个特殊符号&gt;用于段首进行强调，被强调的文字部分将会高亮显示1&gt; 这段文字将被高亮强调显示 这段文字将被高亮强调显示 插入链接或图片引用图片和链接的唯一区别就是在最前方添加一个感叹号。123直接链接：&lt;http://www.baidu.com&gt;[点击跳转至百度](http://www.baidu.com)![图片](https://box.bdimg.com/static/fisp_static/common/img/searchbox/logo_news_276_88_1f9876a.png) 直接链接：http://www.baidu.com点击跳转至百度 列表Markdown支持有序列表和无序列表两种形式：无序列表使用*或+或-标识有序列表使用数字标识 例如1.123456789101112131415* 黄瓜* 玉米* 茄子+ 黄瓜+ 玉米+ 茄子- 黄瓜- 玉米- 茄子1. 黄瓜2. 玉米3. 茄子 黄瓜 玉米 茄子 黄瓜 玉米 茄子 黄瓜 玉米 茄子 黄瓜 玉米 茄子 如果在单一列表项中包含了多个段落，为了保证渲染正常，*与段落首字母之间必须保留四个空格 如果在列表中加入了区块引用，区域引用标记符也需要缩进4个空格12345678910* 段落一 小段一* 段落二 小段二* 段落一 &gt; 区块标记一* 段落二 &gt; 区块标记二 段落一 小段一 段落二 小段二 段落一 区块标记一 段落二 区块标记二 记住一个原则，如果在和列表配合使用的时候出现了问题，就缩进一次，四个空格或者一个制表符代表一次缩进。如果一次缩进没有解决问题，那就两次。 分割线12***--- 对部分文字强调123456789*这里是斜体*_这里是斜体_**这里是加粗**__这里是加粗__上标：O&lt;sub&gt;2&lt;/sub&gt;，下标：3&lt;sup&gt;2&lt;/sup&gt;简称或缩写:The &lt;abbr title=&quot;Hyper Text Markup Language&quot;&gt;HTML&lt;/abbr&gt; specification is maintained by the &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt;. 这里是斜体这里是斜体 这里是加粗这里是加粗 上标：O2，下标：32The HTML specification is maintained by the W3C. 插入表格三个短斜杠左右的冒号用于控制对齐方式只放置左边冒号表示文字居左，只放置右边冒号表示文字居右，如果两边都放置冒号表示文字居中。123表头|条目一|条目二:---:|:---:|:---:项目|项目一|项目二 表头 条目一 条目二 项目 项目一 项目二 特殊符号使用反斜杠\插入语法中用到的特殊符号1234567891011121314151617\\ 反斜线\` 反引号\* 星号\_ 底线\&#123; \&#125; 花括号\[ \] 方括号\( \) 括弧\# 井字号\+ 加号\- 减号\. 英文句点\! 惊叹号&amp;copy; &amp; &amp;uml; &amp;trade; &amp;iexcl; &amp;pound;&amp;amp; &amp;lt; &amp;gt; &amp;yen; &amp;euro; &amp;reg; &amp;plusmn; &amp;para; &amp;sect; &amp;brvbar; &amp;macr; &amp;laquo; &amp;middot;X&amp;sup2; Y&amp;sup3; &amp;frac34; &amp;frac14; &amp;times; &amp;divide; &amp;raquo; \ 反斜线` 反引号* 星号_ 底线{ } 花括号[ ] 方括号( ) 括弧# 井字号+ 加号- 减号. 英文句点! 惊叹号 &copy; &amp; &uml; &trade; &iexcl; &pound;&amp; &lt; &gt; &yen; &euro; &reg; &plusmn; &para; &sect; &brvbar; &macr; &laquo; &middot; X&sup2; Y&sup3; &frac34; &frac14; &times; &divide; &raquo; 文字上色Markdown的最初目标就是为纯写作而生的。因此，它并没有考虑文字颜色这一点。所以，单纯使用Markdown设置文字颜色已经做不到了。但你可以这样做：1&lt;font color=&apos;#ff0000&apos;&gt;红色&lt;/font&gt; 红色 代码12345```javascript function test() &#123; console.log(&quot;Hello world!&quot;); &#125;``` 123function test() &#123; console.log("Hello world!");&#125; 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charest="utf-8" /&gt; &lt;title&gt;Hello world!&lt;/title&gt; &lt;style type="text/css"&gt; ul&#123;list-style: none;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 class="text-xxl"&gt;Hello world!&lt;/h1&gt; &lt;p class="text-green"&gt;Plain text&lt;/p&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
</search>
